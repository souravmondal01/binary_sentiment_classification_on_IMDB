{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravmondal01/binary_sentiment_classification_on_IMDB/blob/main/binary_sentiment_classification_on_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV_inuzz45hp"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6r-1a3u4msj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import re,string,unicodedata\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBt9_0aJ3jJN",
        "outputId": "5b57867a-3be6-4457-a8b4-40376631d0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        }
      ],
      "source": [
        "# Download latest version of the datasets\n",
        "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f082V-ZL5DDo"
      },
      "source": [
        "importing the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "7qNgCzp6y64e",
        "outputId": "6548be98-c2da-48f7-8503-f30fe1663a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-140e846d-1786-4382-ab75-7ef0cf569109\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-140e846d-1786-4382-ab75-7ef0cf569109')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-140e846d-1786-4382-ab75-7ef0cf569109 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-140e846d-1786-4382-ab75-7ef0cf569109');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a9d3902-9862-46ba-b060-5e7d59b19b86\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a9d3902-9862-46ba-b060-5e7d59b19b86')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a9d3902-9862-46ba-b060-5e7d59b19b86 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "imdb_df",
              "summary": "{\n  \"name\": \"imdb_df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# importing the training data\n",
        "imdb_df = pd.read_csv(f'{path}/IMDB Dataset.csv')\n",
        "print(imdb_df.shape)\n",
        "imdb_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDRuiLcH6Eyr"
      },
      "source": [
        "sentiment count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "DEQWaxcJ0SpU",
        "outputId": "3409ce21-d18a-489e-c5ea-b8b76890ad6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    25000\n",
              "negative    25000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#sentiment count\n",
        "imdb_df['sentiment'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUk_RdRyKkSW"
      },
      "source": [
        "## **Spliting the training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxDO97Uj77M3",
        "outputId": "b06b20a2-f981-4838-eae4-1d0c45593f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000,) (40000,)\n",
            "(10000,) (10000,)\n"
          ]
        }
      ],
      "source": [
        "#split the dataset\n",
        "#train dataset\n",
        "train_reviews=imdb_df.review[:40000]\n",
        "train_sentiments=imdb_df.sentiment[:40000]\n",
        "#test dataset\n",
        "test_reviews=imdb_df.review[40000:]\n",
        "test_sentiments=imdb_df.sentiment[40000:]\n",
        "print(train_reviews.shape,train_sentiments.shape)\n",
        "print(test_reviews.shape,test_sentiments.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NazLK9scLgz6"
      },
      "source": [
        "## **Text normalization**\n",
        "**`tokenizer=ToktokTokenizer()`**  \n",
        "- This line initializes an instance of the `ToktokTokenizer` class from the `nltk.tokenize` module.\n",
        "- `ToktokTokenizer` is a text tokenizer, which splits a sentence or paragraph into individual tokens (words or punctuation marks).  \n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "\n",
        "tokenizer = ToktokTokenizer()\n",
        "tokens = tokenizer.tokenize(\"This is an example sentence.\")\n",
        "print(tokens)\n",
        "# Output: ['This', 'is', 'an', 'example', 'sentence', '.']\n",
        "```\n",
        "**`nltk.download('stopwords')`**  \n",
        "- This command downloads the predefined stopwords dataset from the NLTK (Natural Language Toolkit) library.\n",
        "- **What Are Stopwords?**:\n",
        " - Stopwords are commonly used words in a language (e.g., \"is\", \"the\", \"and\") that often don’t contribute much meaning to the text and are usually removed during preprocessing for natural language processing (NLP) tasks.\n",
        "\n",
        "**`stopword_list=nltk.corpus.stopwords.words('english')`**  \n",
        "- This line loads the list of English stopwords from the downloaded stopwords dataset into the variable `stopword_list`.\n",
        "\n",
        "For example:\n",
        "```python\n",
        "text = \"This is an example sentence.\"\n",
        "tokens = tokenizer.tokenize(text)  # Tokenize the text\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stopword_list]  # Remove stopwords\n",
        "print(filtered_tokens)\n",
        "# Output: ['example', 'sentence']\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwqhM04ZK3LV",
        "outputId": "067ed4f8-b8ec-4c8f-eb90-32d1ad83d7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Tokenization of text\n",
        "tokenizer=ToktokTokenizer()\n",
        "# Downloading Stopwords\n",
        "nltk.download('stopwords')\n",
        "#Setting English stopwords\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bmxYnm2NLnW"
      },
      "source": [
        "# Removing html strips and noise text\n",
        "* Input Review Text: \"This is an amazing movie! [Spoiler Alert] Check out <a href='link'>this link</a> for more details.\"\n",
        "* HTML Removal (strip_html): \"This is an amazing movie! [Spoiler Alert] Check out this link for more details.\"\n",
        "* Square Bracket Removal (remove_between_square_brackets): \"This is an amazing movie! Check out this link for more details.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "povpiOPrLm5a"
      },
      "outputs": [],
      "source": [
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\") # Parses the input text as if it were an HTML document.\n",
        "    return soup.get_text() # Extracts the plain text by removing all HTML tags and structure.\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text) #\\[ and \\]: Match the literal square brackets. [^]]*: Matches any characters inside the brackets, except the closing bracket. Replaces the matched text with an empty string (''), effectively removing it.\n",
        "\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "imdb_df['review']=imdb_df['review'].apply(denoise_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKA0fIicvNLa"
      },
      "source": [
        "# Removing special characters\n",
        "\n",
        "* This function removes special characters (e.g., punctuation, symbols) from a given text while retaining alphanumeric characters and spaces.\n",
        "* Input Review Text: \"Wow! This movie is amazing :) @user123 #MustWatch.\"\n",
        "* Resulting Text: \"Wow This movie is amazing  user123 MustWatch\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VBWFer3wzZl"
      },
      "outputs": [],
      "source": [
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern = r'[^a-zA-Z0-9\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr9oCqLmxlyi"
      },
      "source": [
        "# Text stemming\n",
        "- Stemming reduces words to their root or base form by removing suffixes. For example:\n",
        " - \"running\" → \"run\"\n",
        " - \"easily\" → \"easili\"\n",
        " - \"studies\" → \"studi\"\n",
        "* It simplifies words, which can help reduce vocabulary size in Natural Language Processing (NLP) tasks.\n",
        "\n",
        "\n",
        "* **Input Review Text:** \"The cats were running swiftly towards the forest.\"\n",
        "* **Stemming Each Word and Joining Back:** \"the cat were run swiftli toward the forest\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmpaneOTw5y8"
      },
      "outputs": [],
      "source": [
        "#Stemming the text\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer() # PorterStemmer is a popular stemming algorithm provided by the NLTK library. It applies a set of rules to systematically reduce words to their base form.\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()]) # For each word in the list, the stem() function of the PorterStemmer instance (ps) is applied. The result is a list of stemmed words. Then combines the stemmed words into a single string, separated by spaces.\n",
        "    return text\n",
        "#Apply function on review column\n",
        "imdb_df['review']=imdb_df['review'].apply(simple_stemmer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Removing stopwords**\n",
        "* Stopwords are common words (e.g., \"the\", \"is\", \"in\", \"and\") that appear frequently in a language but often carry little meaningful information for tasks like text classification or sentiment analysis. Removing stopwords helps reduce the noise in the text.\n",
        "* **Input Text:** \"This is a great movie with wonderful acting and an amazing story.\"\n",
        "* **Tokenize Text:** [\"This\", \"is\", \"a\", \"great\", \"movie\", \"with\", \"wonderful\", \"acting\", \"and\", \"an\", \"amazing\", \"story\"]\n",
        "* **Filter Stopwords:** [\"great\", \"movie\", \"wonderful\", \"acting\", \"amazing\", \"story\"]\n",
        "* **Join Tokens:** \"great movie wonderful acting amazing story\"\n"
      ],
      "metadata": {
        "id": "gtJppShFIpxp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ79_iU4xyLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b181937-0c40-498c-acbb-91d37f23681e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'now', 'as', 'any', 'yourselves', \"hasn't\", 'ourselves', 'o', 'again', 'be', 'having', 'where', 'our', \"wouldn't\", 'hasn', 're', 'up', 'until', 'above', \"mustn't\", 'himself', \"needn't\", 'just', 'those', 'hadn', 'own', 'it', 'same', 'only', 'about', 'his', 'were', 'aren', 'after', 'some', 'doesn', 'further', 'to', 'her', 'an', 'by', 'from', 'few', 'was', \"doesn't\", 'didn', 'under', \"weren't\", \"she's\", 'did', 'ours', 'over', 'but', \"hadn't\", 'what', 'because', 'how', 'being', 'against', 'been', 've', 'shan', 'has', 'your', 'm', 'into', 'each', 'in', 'other', 'hers', 'during', 'can', 'through', 'doing', 'and', 'that', 'you', 'their', 'this', 'very', 'should', 'll', \"haven't\", 'a', 'had', \"mightn't\", 'wouldn', 'nor', 'is', 'itself', 'are', 'do', 'or', 'why', 'than', 't', 'there', 'ain', 'out', 'too', 'so', \"won't\", 'does', 'which', 'he', 'couldn', 'haven', 'no', 'don', 'i', 'then', 'needn', 'ma', \"you'll\", \"you've\", 'isn', 's', \"should've\", 'yourself', 'd', 'will', 'with', 'of', 'when', 'below', 'once', 'the', 'all', 'if', 'him', 'most', 'they', \"didn't\", \"aren't\", 'themselves', \"you'd\", 'y', 'both', 'its', 'on', 'between', 'myself', 'we', 'mightn', \"couldn't\", 'at', 'wasn', \"you're\", 'my', \"it's\", 'before', \"shan't\", \"shouldn't\", 'yours', 'for', 'here', 'mustn', 'more', 'shouldn', 'whom', 'she', 'these', \"that'll\", 'me', 'who', 'am', 'down', \"don't\", 'such', \"isn't\", 'weren', 'herself', 'won', 'theirs', \"wasn't\", 'off', 'them', 'while', 'not', 'have'}\n"
          ]
        }
      ],
      "source": [
        "#set stopwords to english\n",
        "stop=set(stopwords.words('english')) # stopwords.words('english') loads the list of stopwords for the English language from the NLTK library.\n",
        "# A set is used for efficient membership testing when checking if a word is a stopword.\n",
        "print(stop) # Displays the list of stopwords to verify or understand what will be removed.\n",
        "\n",
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text) # The input text is split into individual words (tokens) using tokenizer.tokenize.\n",
        "    tokens = [token.strip() for token in tokens] # Any leading or trailing whitespace in tokens is removed.\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list] # Directly checks tokens without converting to lowercase.\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list] # Converts tokens to lowercase before checking membership in stopword_list.\n",
        "    filtered_text = ' '.join(filtered_tokens) # Combines the filtered tokens into a single string, separated by spaces.\n",
        "    return filtered_text # Outputs the text with stopwords removed.\n",
        "#Apply function on review column\n",
        "imdb_df['review'] = imdb_df['review'].apply(remove_stopwords) # Removes stopwords from the reviews and updates the column with the cleaned text."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split reviews in train & test"
      ],
      "metadata": {
        "id": "F2Rkjd5Jrr27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalized train reviews\n",
        "norm_train_reviews=imdb_df.review[:40000] # Extracts the first 40,000 reviews from the review column of the imdb_data DataFrame.\n",
        "norm_test_reviews=imdb_df.review[40000:]"
      ],
      "metadata": {
        "id": "6ZwTpEEYnjg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of words Model\n",
        "The code is converting text data (reviews) into a format called Bag of Words (BoW). This is a common way to prepare text for machine learning models. It counts how many times each word (or set of words) appears in the text.\n",
        "\n",
        "```python\n",
        "cv = CountVectorizer(min_df=0, max_df=1, binary=False, ngram_range=(1,3))\n",
        "```\n",
        "\n",
        "- **`min_df=0`:** No filtering for rarely used words. Even words that appear in just one document will be included in the vocabulary.\n",
        "\n",
        "- **`max_df=1`:** No filtering for commonly used words.** Even words that appear in all documents will be included in the vocabulary.\n",
        "#### Example:\n",
        "If `max_df=0.8`, words that appear in **80% or more of the documents** will be ignored.\n",
        "\n",
        "\n",
        "  - **`ngram_range=(1,3)`** means it considers:\n",
        "    - Single words (unigrams, e.g., \"love\"),\n",
        "    - Two-word combinations (bigrams, e.g., \"love machine\"),\n",
        "    - Three-word combinations (trigrams, e.g., \"machine learning is\").\n",
        "  - **`binary=False`** means it counts how many times each word or phrase appears.\n",
        "\n",
        "* ngram_range=(1,3) means it considers: Single words (unigrams, e.g., \"love\"), Two-word combinations (bigrams, e.g., \"love machine\"), Three-word combinations (trigrams, e.g., \"machine learning is\")\n",
        "* binary=False means it counts how many times each word or phrase appears.\n",
        "\n",
        "```python\n",
        "cv_train_reviews = cv.fit_transform(norm_train_reviews)\n",
        "```\n",
        "- **`fit_transform`** does two things:\n",
        "  - **`fit`**: It learns all the unique words/phrases from the training data.\n",
        "  - **`transform`**: It creates a table (matrix) where:\n",
        "    - Rows = individual reviews,\n",
        "    - Columns = words or phrases from the vocabulary,\n",
        "    - Each cell = how many times a word/phrase appears in that review.\n",
        "\n",
        "```python\n",
        "cv_test_reviews = cv.transform(norm_test_reviews)\n",
        "```\n",
        "- The test data is transformed using the same vocabulary as the training data.\n",
        "\n",
        "```python\n",
        "print('BOW_cv_train:', cv_train_reviews.shape)\n",
        "print('BOW_cv_test:', cv_test_reviews.shape)\n",
        "```\n",
        "- **Shape** tells you:\n",
        "  - **Rows**: Number of reviews in the dataset.\n",
        "  - **Columns**: Total number of unique words/phrases found in the training data.\n",
        "\n",
        "Example:\n",
        "If the training data has 100 reviews and 5000 unique words/phrases:\n",
        "- Output: `BOW_cv_train: (100, 5000)`\n",
        "\n",
        "---\n",
        "\n",
        "### Summary Example:\n",
        "Imagine you have these two reviews:\n",
        "\n",
        "1. \"I love learning.\"\n",
        "2. \"Learning is fun.\"\n",
        "\n",
        "**Vocabulary (with ngrams):**\n",
        "- Unigrams: `[\"i\", \"love\", \"learning\", \"is\", \"fun\"]`\n",
        "- Bigrams: `[\"i love\", \"love learning\", \"learning is\", \"is fun\"]`\n",
        "- Trigrams: `[\"i love learning\", \"learning is fun\"]`\n",
        "\n",
        "**Matrix:**\n",
        "\n",
        "|                | i | love | learning | is | fun | i love | love learning | learning is | learning is fun |\n",
        "|----------------|---|------|----------|----|-----|--------|---------------|-------------|-----------------|\n",
        "| Review 1:      | 1 | 1    | 1        | 0  | 0   | 1      | 1             | 0           | 0               |\n",
        "| Review 2:      | 0 | 0    | 1        | 1  | 1   | 0      | 0             | 1           | 1               |\n",
        "\n",
        "This is how your text is converted into numbers for machine learning models!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KfBVp32UdOcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv=CountVectorizer(min_df=0.0,max_df=1.0,binary=False,ngram_range=(1,3))\n",
        "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
        "cv_test_reviews=cv.transform(norm_test_reviews)\n",
        "\n",
        "print('BOW_cv_train:',cv_train_reviews.shape)\n",
        "print('BOW_cv_test:',cv_test_reviews.shape)\n"
      ],
      "metadata": {
        "id": "P1taQgtTsEyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb08067-cc48-498f-b709-b6e90b2bc33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOW_cv_train: (40000, 7164332)\n",
            "BOW_cv_test: (10000, 7164332)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Labeling the sentiment text**\n",
        "```python\n",
        "lb = LabelBinarizer()\n",
        "```\n",
        "- The `LabelBinarizer` is a utility that converts categorical labels (e.g., 'positive' and 'negative') into binary format:\n",
        "  - One class will be represented as `1`.\n",
        "  - The other class will be represented as `0`.\n",
        "\n",
        "```python\n",
        "sentiment_data = lb.fit_transform(imdb_data['sentiment'])\n",
        "```\n",
        "- **What it does**:\n",
        "  - The `fit_transform()` method combines two actions:\n",
        "    1. **`fit`**: Identifies the unique labels in the `sentiment` column (e.g., 'positive' and 'negative').\n",
        "    2. **`transform`**: Converts each label into its binary representation.\n",
        "  - For example:\n",
        "    - If the sentiment column contains:\n",
        "      ```python\n",
        "      ['positive', 'negative', 'positive', 'negative']\n",
        "      ```\n",
        "      The binary representation will be:\n",
        "      ```python\n",
        "      [[1],\n",
        "       [0],\n",
        "       [1],\n",
        "       [0]]\n",
        "      ```\n",
        "\n",
        "- **Extensibility**:\n",
        "  - If the dataset contained more than two unique sentiment labels, you would use tools like `OneHotEncoder` for multi-class encoding instead.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L45fT6lxZmLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#labeling the sentient data\n",
        "lb=LabelBinarizer()\n",
        "#transformed sentiment data\n",
        "sentiment_data=lb.fit_transform(imdb_df['sentiment'])\n",
        "print(sentiment_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgu28VLvvqLM",
        "outputId": "ab392445-f8c0-4439-a7ac-daaa02b046d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **How to Verify What `0` Means**\n",
        "Here, the index of the sentiment corresponds to the encoded value:\n",
        "- `'negative'` → `0`\n",
        "- `'positive'` → `1`\n",
        "\n"
      ],
      "metadata": {
        "id": "X52lgVQ7SLJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mapping: \", {i: sentiment for i, sentiment in enumerate(lb.classes_)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa7aDDY6R4pt",
        "outputId": "e7a79a9a-ad11-4329-c5bc-6c0c9c420407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping:  {0: 'negative', 1: 'positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Split the sentiment tdata**"
      ],
      "metadata": {
        "id": "SiNoFc2sacV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Spliting the sentiment data\n",
        "train_sentiments=sentiment_data[:40000]\n",
        "test_sentiments=sentiment_data[40000:]\n",
        "print(train_sentiments)\n",
        "print(test_sentiments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNfHaphiwVMR",
        "outputId": "a089e01c-270f-4ea1-f0f9-902599f5613a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelling the dataset using Logistic Regression Model**\n",
        "\n",
        "```python\n",
        "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=42)\n",
        "```\n",
        "- **`LogisticRegression`**:\n",
        "  - A supervised learning algorithm used for classification tasks, such as binary sentiment classification (e.g., positive vs. negative).\n",
        "  - Logistic regression predicts the probability of a class and outputs `1` or `0` (or probabilities for multi-class problems).\n",
        "\n",
        "- **Parameters**:\n",
        "  - `penalty='l2'`: Adds **L2 regularization** to prevent overfitting by penalizing large coefficients. This is a regularization term that helps the model generalize better.\n",
        "  - `max_iter=500`: Sets the maximum number of iterations for the optimization algorithm to converge. Increasing this ensures the model has enough time to find the optimal solution.\n",
        "  - `C=1`: Inverse of regularization strength (smaller values mean stronger regularization). A value of `1` applies moderate regularization.\n",
        "  - `random_state=42`: Sets a random seed for reproducibility of the results."
      ],
      "metadata": {
        "id": "kDT4puo-bUSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Logistic Regression Model\n",
        "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
        "# Fit the Model to the Training Data\n",
        "lr_bow=lr.fit(cv_train_reviews,train_sentiments)\n",
        "print(lr_bow)"
      ],
      "metadata": {
        "id": "mvO8jME8wf3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6171e096-b6c3-4dd7-fd22-e385037bf8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the model for bag of words\n",
        "lr_bow_predict=lr.predict(cv_test_reviews)\n",
        "print(lr_bow_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djNjylHZbTOr",
        "outputId": "c3972bc4-4a43-4425-d526-b0ff6710b8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 ... 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy score for bag of words\n",
        "lr_bow_score=accuracy_score(test_sentiments,lr_bow_predict)\n",
        "print(\"lr_bow_score :\",lr_bow_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye0APmIVdiSy",
        "outputId": "f355c438-e6b8-4bb4-fb59-e9b986c0d1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr_bow_score : 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification report for bag of words\n",
        "lr_bow_report=classification_report(test_sentiments,lr_bow_predict,target_names=['Positive','Negative'])\n",
        "print(lr_bow_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1QvPZ14d8fA",
        "outputId": "9845c0cc-c997-42ba-e59f-cfad83511b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.90      0.90      0.90      4993\n",
            "    Negative       0.90      0.90      0.90      5007\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix for bag of words\n",
        "cm_bow=confusion_matrix(test_sentiments,lr_bow_predict,labels=[1,0])\n",
        "print(cm_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwdQfwATd-pQ",
        "outputId": "02e92ecd-fb91-4186-d046-790d1d5c025e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4515  492]\n",
            " [ 508 4485]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to combine reviews, actual sentiments, and predictions\n",
        "results_df = pd.DataFrame({\n",
        "    'Review': test_reviews.reset_index(drop=True),  # Reset index of test_reviews\n",
        "    'Actual Sentiment': test_sentiments.flatten(),     # Ground truth labels (flattened)\n",
        "    'Predicted Sentiment': lr_bow_predict    # Predictions made by the model\n",
        "})\n",
        "\n",
        "# View the first few rows of the DataFrame\n",
        "print(results_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT13Ux-KeBIs",
        "outputId": "8aa93abe-3e4c-4893-a147-cbbf8230488e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  Actual Sentiment  \\\n",
            "0  First off I want to say that I lean liberal on...                 0   \n",
            "1  I was excited to see a sitcom that would hopef...                 0   \n",
            "2  When you look at the cover and read stuff abou...                 0   \n",
            "3  Like many others, I counted on the appearance ...                 0   \n",
            "4  This movie was on t.v the other day, and I did...                 0   \n",
            "\n",
            "   Predicted Sentiment  \n",
            "0                    0  \n",
            "1                    0  \n",
            "2                    1  \n",
            "3                    0  \n",
            "4                    0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a specific review (e.g., at index 0)\n",
        "sample_index = 0\n",
        "print(\"Review:\", results_df.loc[sample_index, 'Review'])\n",
        "print(\"Actual Sentiment:\", results_df.loc[sample_index, 'Actual Sentiment'])\n",
        "print(\"Predicted Sentiment:\", results_df.loc[sample_index, 'Predicted Sentiment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NllTmDRCmyKs",
        "outputId": "9ca45481-c40f-4055-c2e5-3884dbe81512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: First off I want to say that I lean liberal on the political scale and I found the movie offensive. I managed to watch the whole doggone disgrace of a film . This movie brings a low to original ideas. Yes it was original thus my 2 stars instead of 1. Are our film writers that uncreative that they can only come up with this?? Acting was horrible , and the characters were unlikeable for the most part. The lead lady in the story had no good qualities at all. They made her bf into some sort of a bad guy and I did not see that at all. Maybe I missed something , I do not know.He was the most down to earth, relevant character in the movie. I did not shell out any money for this garbage. I almost wish PETA would come to the rescue of this awful, offensive movie and form a protest. DISGUSTING thats all I have to say anymore !\n",
            "Actual Sentiment: 0\n",
            "Predicted Sentiment: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelling the dataset using Random Forest Classifier Model**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T273Lgqbn4kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Initialize the Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
        "# Train the model on the Bag-of-Words data\n",
        "rf.fit(cv_train_reviews, train_sentiments)\n",
        "# Predict the sentiments for the test data\n",
        "rf_bow_predict = rf.predict(cv_test_reviews)"
      ],
      "metadata": {
        "id": "UCKTYu1ym0P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy score for bag of words\n",
        "rf_bow_score=accuracy_score(test_sentiments,rf_bow_predict)\n",
        "print(\"rf_bow_score :\",rf_bow_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy7wEgPoogv-",
        "outputId": "ec894216-ac8b-4aea-c5c6-8d0f8affe632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rf_bow_score : 0.8568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix for bag of words\n",
        "cm_bow=confusion_matrix(test_sentiments,rf_bow_predict,labels=[1,0])\n",
        "print(cm_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsx8qI9fEOtE",
        "outputId": "c8292302-88c7-4dbd-fe6c-174dd649b512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4447  560]\n",
            " [ 872 4121]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to combine reviews, actual sentiments, and predictions\n",
        "results_df = pd.DataFrame({\n",
        "    'Review': test_reviews.reset_index(drop=True),  # Reset index of test_reviews\n",
        "    'Actual Sentiment': test_sentiments.flatten(),     # Ground truth labels (flattened)\n",
        "    'Predicted Sentiment': rf_bow_predict    # Predictions made by the model\n",
        "})\n",
        "\n",
        "# View the first few rows of the DataFrame\n",
        "print(results_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj5qEQz5Qqbr",
        "outputId": "0d55e930-f54d-4b0e-b357-196904fbb61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  Actual Sentiment  \\\n",
            "0  First off I want to say that I lean liberal on...                 0   \n",
            "1  I was excited to see a sitcom that would hopef...                 0   \n",
            "2  When you look at the cover and read stuff abou...                 0   \n",
            "3  Like many others, I counted on the appearance ...                 0   \n",
            "4  This movie was on t.v the other day, and I did...                 0   \n",
            "\n",
            "   Predicted Sentiment  \n",
            "0                    0  \n",
            "1                    0  \n",
            "2                    1  \n",
            "3                    0  \n",
            "4                    0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect a specific review (e.g., at index 10)\n",
        "sample_index = 10\n",
        "print(\"Review:\", results_df.loc[sample_index, 'Review'])\n",
        "print(\"Actual Sentiment:\", results_df.loc[sample_index, 'Actual Sentiment'])\n",
        "print(\"Predicted Sentiment:\", results_df.loc[sample_index, 'Predicted Sentiment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz_hdAGYSinY",
        "outputId": "969e433d-e4ef-4887-8a00-f9d0c88b2c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: \"Mr. Bug Goes To Town\" was the last major achievement the Fleischer studios produced. The quality of the Superman series produced at the same time is evident in this extraordinary film.<br /><br />The music and lyrics by Frank Loesser and Hoagy Carmichael (with assistance by Flieshcer veteran Sammy Timberg are quite good, but not as much as the scoring of the picture by Leigh Harline who also scored Snow White for Disney. Harline's \"atmospheric music\" is superb, and a treat for the ears.<br /><br />The layout and staging of the picture was years ahead of it's time, and once again the Fleischer's background artists outdid themselves. The techincolored beauty of the film cannot be denied, and while Hoppity the grasshopper is the star, the characters of Swat the Fly and Smack the Mosquito steal the picture. Swat's voicing by Jack Mercer (of Popeye fame) is priceless. Kenny Gardner (brother-in-law) of Guy Lombardo...and a featured vocalist in his band...does his usual pleasant job in the role of Dick Dickinsen.<br /><br />The movie has been criticized for all the wrong reasons. The Fleischer Studios were animation experts par excellence and this shows very clearly in the finished product. The movie is tuneful, the story great for all ages, and the final scenes of the bugs scrambling for their lives upon a rising skyscraper is some of the best staging and animation of any animated film past and present.<br /><br />Do not miss this wonderfully hand drawn film. Also don't fail to appreciate the title sequence with the most elaborate example of Max Fleischer's remarkable 3-D sterioptical process which took four months to construct and employed 16,000 tiny panes of glass in the \"electrified\" buildings of Manhattan.<br /><br />Do not miss Mr. Bug Goes To Town...aka Hoppity Goes To Town. I'll wager you'll be bug eyed at the results!\n",
            "Actual Sentiment: 1\n",
            "Predicted Sentiment: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZgYSg6jFSkF4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNEtlIgMaHikkhAa1/HRp/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}